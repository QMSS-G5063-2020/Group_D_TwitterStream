---
title: "Untitled"
author: "Lemon Reimer"
date: "2/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(rtweet)
library(ggplot2)
library(dplyr)
library(quanteda)
library(tidytext)
library(tm)

#points to where python is on your local
use_python("C:/Users/swagj/AppData/Local/Continuum/anaconda3/python.exe")

#sets base directory
knitr::opts_knit$set(root.dir = normalizePath("C:\\Users\\swagj\\Documents\\GitHub\\TwitterNetworkStreaming\\Lemon_Streamer_Tweepy"))
```

```{r initialize python object}
source_python("Lemon_ML_NoClass.py", convert = F)

#import some python modules
main <- import_main()
builtins <- import_builtins()

py$os$chdir("C:\\Users\\swagj\\Documents\\GitHub\\TwitterNetworkStreaming\\Lemon_Streamer_Tweepy")
#import(Lemon_Streamer_Tweepy, convert = F)
#myML <- reticulate::import_from_path(Lemon_Streamer_Tweepy, path = "C:\\Users\\swagj\\Documents\\GitHub\\TwitterNetworkStreaming\\")
```

```{r API keys}
#after the first call, this info is saved to renviron

#ckey=""
#csecret=""
#atoken=""
#asecret=""

#token <- create_token(
  #app = "LemonAPIApp",
  #consumer_key = ckey,
  #consumer_secret = csecret,
  #access_token = atoken,
  #access_secret = asecret)
```

```{r using python ML}
my_vec_tfidf = py_load_object("tfidf.pkl")
pca = py_load_object("pca.pkl")
clf_pca = py_load_object("clf_pca.pkl")

query <- "COVID"
streamtime <- 2 #number of seconds for each sampling from twitter
filename <- "teststream.json"

timer <- 1 #initialize timer
rt <- stream_tweets(q = query, timeout = streamtime, file_name = filename) #initialize dataframe
rt <- rt[rt$lang == "en",] #remove non-english text
class_list = c()

repeat { #start repeat statement
  temp_rt <- stream_tweets(q = query, timeout = streamtime, file_name = filename) #stream new data
  temp_rt <- temp_rt[temp_rt$lang == "en",] 
  rt <- rbind(rt, temp_rt) #add new data to dataframe
  timer <- timer + 1 #add loop to timer

  #print(ggplot(rt, aes(x = source)) + geom_bar()) #example of bar plot, rescales as count increases!
  #print(ts_plot(rt, by = 'secs', trim = 1)) #example of line plot, rescales as count increases!
  
  #myts <- rt %>% group_by(source) %>% ts_plot(., by = "secs", trim = 1) + ggplot2::labs(title = "Tweets over time") 
  #print(myts) #more complex version of the line plot example
  for (tweet in temp_rt$text){
      test = py$clean_up_sw(tweet)
      class_pred = py$NewPredict(my_vec_tfidf = my_vec_tfidf, pca = pca, clf_pca = clf_pca, data = test)
      class_list = c(class_list, class_pred[1])
  }
  
  class_df <- data.frame("class" = matrix(unlist(class_list), nrow=length(class_list), byrow=T))
  print(ggplot(class_df, aes(x = class)) + geom_bar())
  
  if (timer == 5){ #break statement, stream ends after 5 loops
    break
  }
}
```

```{r figuring out how to classify}
#my_vec_tfidf = py$pickle$load(builtins$open(py$os$path$realpath("tfidf.pkl"), "rb"))
#pca = py$pickle$load(builtins$open(py$os$path$realpath("pca.pkl"), "rb"))
#clf_pca = py$pickle$load(builtins$open(py$os$path$realpath("clf_pca.pkl"), "rb"))

my_vec_tfidf = py_load_object("tfidf.pkl")
pca = py_load_object("pca.pkl")
clf_pca = py_load_object("clf_pca.pkl")

test = py$clean_up_sw(rt$text[1])

print(builtins$type(test))
print(typeof(test))

class_pred = py$NewPredict(my_vec_tfidf = my_vec_tfidf, pca = pca, clf_pca = clf_pca, data = test)
```

```{r}
for (tweet in temp_rt$text){
    test = py$clean_up_sw(tweet)
    class_pred = py$NewPredict(my_vec_tfidf = my_vec_tfidf, pca = pca, clf_pca = clf_pca, data = test)
    class_list = c(class_list, class_pred[1])
  }
  class_df <- data.frame("class" = matrix(unlist(class_list), nrow=length(class_list), byrow=T))
  print(ggplot(class_df, aes(x = class)) + geom_bar())
```

```{r}
nrc <- get_sentiments("nrc")

countClass <- function(x){
  x <- removePunctuation(x)
  x <- gsub("[^A-Za-z0-9]+", " ", x)
  x <- tolower(x)
  x <- removeWords(x, stopwords("en"))
  x <- trimws(x)
  x <- stripWhitespace(x)
  try(
    #temp_sent <- table(nrc[nrc$word %in% as.list(unlist(strsplit(x, "\\s+")[[1]])), "sentiment"], decreasing = T)
    temp_sent <- names(table(nrc[nrc$word %in% as.character(quanteda::tokens(x)), "sentiment" ]))[1]
    )
  return(temp_sent)
}
#try(df$sentnrc[i] <- names(table(gs[gs$word %in% as.character(quanteda::tokens(df$blurb2[i])), "sentiment" ]))[1])
```

```{r using R count classifier}
query <- "COVID"
streamtime <- 2 #number of seconds for each sampling from twitter
filename <- "teststream.json"

timer <- 1 #initialize timer
rt <- stream_tweets(q = query, timeout = streamtime, file_name = filename) #initialize dataframe
rt <- rt[rt$lang == "en",] #remove non-english text
class_list = c()

repeat { #start repeat statement
  temp_rt <- stream_tweets(q = query, timeout = streamtime, file_name = filename) #stream new data
  temp_rt <- temp_rt[temp_rt$lang == "en",] 
  rt <- rbind(rt, temp_rt) #add new data to dataframe
  timer <- timer + 1 #add loop to timer

  #print(ggplot(rt, aes(x = source)) + geom_bar()) #example of bar plot, rescales as count increases!
  #print(ts_plot(rt, by = 'secs', trim = 1)) #example of line plot, rescales as count increases!
  
  #myts <- rt %>% group_by(source) %>% ts_plot(., by = "secs", trim = 1) + ggplot2::labs(title = "Tweets over time") 
  #print(myts) #more complex version of the line plot example
  for (tweet in temp_rt$text){
      #test = py$clean_up_sw(tweet)
      class_list = c(class_list, countClass(tweet))
  }
  
  class_df <- data.frame("class" = matrix(unlist(class_list), nrow=length(class_list), byrow=T))
  print(ggplot(class_df, aes(x = class)) + geom_bar())
  
  if (timer == 5){ #break statement, stream ends after 5 loops
    break
  }
}
```
